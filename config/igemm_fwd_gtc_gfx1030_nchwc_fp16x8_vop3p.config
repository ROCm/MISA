[codegen]
arch = 'gfx1030'
code_object = 'cov3'
mode = 'flat'

#########################################################################################
#--------------------------- 256x128x32
[igemm_fwd_gtc]
gemm_m_per_block         = 256
gemm_n_per_block         = 128
gemm_k_per_block         = 32
lanegroup_tile_m         = 8
lanegroup_wave_m         = 4
lanegroup_repeat_m       = 2
lanegroup_tile_n         = 16
lanegroup_wave_n         = 2
lanegroup_repeat_n       = 4
tensor_a_thread_lengths  = [1, 1, 1, 32]       # 1xCEx1xK/Vec-c
tensor_a_cluster_lengths = [1, 4, 1, 64]       # 1xCEx1xK
tensor_b_thread_lengths  = [1, 1, 2,  8]       # 1xCExNB0xVec-c
tensor_b_cluster_lengths = [1, 4, 1, 64]       # 1xCEx1xNB1
direction                = "fwd"
precision                = "fp16"
tensor_layout            = ['nchwc_cyxkc', 'nchwc_kcyxc']
nxb                      = 0
nxe                      = 1
wavefront_size           = 32
cumode                   = 0
vector_c                 = 8

[igemm_fwd_gtc]
gemm_m_per_block         = 256
gemm_n_per_block         = 128
gemm_k_per_block         = 32
lanegroup_tile_m         = 8
lanegroup_wave_m         = 4
lanegroup_repeat_m       = 2
lanegroup_tile_n         = 16
lanegroup_wave_n         = 2
lanegroup_repeat_n       = 4
tensor_a_thread_lengths  = [1, 1, 1, 32]       # 1xCEx1xK/Vec-c
tensor_a_cluster_lengths = [1, 4, 1, 64]       # 1xCEx1xK
tensor_b_thread_lengths  = [1, 1, 2,  8]       # 1xCExNB0xVec-c
tensor_b_cluster_lengths = [1, 4, 1, 64]       # 1xCEx1xNB1
direction                = "fwd"
precision                = "fp16"
tensor_layout            = ['nchwc_cyxkc', 'nchwc_kcyxc']
nxb                      = 0
nxe                      = 0
wavefront_size           = 32
cumode                   = 0
vector_c                 = 8

#--------------------------- 128x256x32
[igemm_fwd_gtc]
gemm_m_per_block         = 128
gemm_n_per_block         = 256
gemm_k_per_block         = 32
lanegroup_tile_m         = 8
lanegroup_wave_m         = 2
lanegroup_repeat_m       = 2
lanegroup_tile_n         = 16
lanegroup_wave_n         = 4
lanegroup_repeat_n       = 4
tensor_a_thread_lengths  = [1, 1, 1, 16]       # 1xCEx1xK/Vec-c
tensor_a_cluster_lengths = [1, 4, 1, 64]       # 1xCEx1xK
tensor_b_thread_lengths  = [1, 1, 4,  8]       # 1xCExNB0xVec-c
tensor_b_cluster_lengths = [1, 4, 1, 64]       # 1xCEx1xNB1
direction                = "fwd"
precision                = "fp16"
tensor_layout            = ['nchwc_cyxkc', 'nchwc_kcyxc']
nxb                      = 0
nxe                      = 1
wavefront_size           = 32
cumode                   = 0
vector_c                 = 8

[igemm_fwd_gtc]
gemm_m_per_block         = 128
gemm_n_per_block         = 256
gemm_k_per_block         = 32
lanegroup_tile_m         = 8
lanegroup_wave_m         = 2
lanegroup_repeat_m       = 2
lanegroup_tile_n         = 16
lanegroup_wave_n         = 4
lanegroup_repeat_n       = 4
tensor_a_thread_lengths  = [1, 1, 1, 16]       # 1xCEx1xK/Vec-c
tensor_a_cluster_lengths = [1, 4, 1, 64]       # 1xCEx1xK
tensor_b_thread_lengths  = [1, 1, 4,  8]       # 1xCExNB0xVec-c
tensor_b_cluster_lengths = [1, 4, 1, 64]       # 1xCEx1xNB1
direction                = "fwd"
precision                = "fp16"
tensor_layout            = ['nchwc_cyxkc', 'nchwc_kcyxc']
nxb                      = 0
nxe                      = 0
wavefront_size           = 32
cumode                   = 0
vector_c                 = 8

# #--------------------------- 224x128x64
# [igemm_fwd_gtc]
# gemm_m_per_block         = 224
# gemm_n_per_block         = 128
# gemm_k_per_block         = 64
# lanegroup_tile_m         = 8
# lanegroup_wave_m         = 4
# lanegroup_repeat_m       = 7
# lanegroup_tile_n         = 16
# lanegroup_wave_n         = 2
# lanegroup_repeat_n       = 1
# tensor_a_thread_lengths  = [1, 1, 1, 56]       # 1xCEx1xK/Vec-c
# tensor_a_cluster_lengths = [1, 8, 1, 32]       # 1xCEx1xK
# tensor_b_thread_lengths  = [1, 1, 4,  8]       # 1xCExNB0xVec-c
# tensor_b_cluster_lengths = [1, 8, 1, 32]       # 1xCEx1xNB1
# direction                = "fwd"
# precision                = "fp16"
# tensor_layout            = ['nchwc_cyxkc', 'nchwc_kcyxc']
# nxb                      = 0
# nxe                      = 1
# wavefront_size           = 32
# cumode                   = 0
# vector_c                 = 8
# 
# [igemm_fwd_gtc]
# gemm_m_per_block         = 224
# gemm_n_per_block         = 128
# gemm_k_per_block         = 64
# lanegroup_tile_m         = 8
# lanegroup_wave_m         = 4
# lanegroup_repeat_m       = 7
# lanegroup_tile_n         = 16
# lanegroup_wave_n         = 2
# lanegroup_repeat_n       = 1
# tensor_a_thread_lengths  = [1, 1, 1, 56]       # 1xCEx1xK/Vec-c
# tensor_a_cluster_lengths = [1, 8, 1, 32]       # 1xCEx1xK
# tensor_b_thread_lengths  = [1, 1, 4,  8]       # 1xCExNB0xVec-c
# tensor_b_cluster_lengths = [1, 8, 1, 32]       # 1xCEx1xNB1
# direction                = "fwd"
# precision                = "fp16"
# tensor_layout            = ['nchwc_cyxkc', 'nchwc_kcyxc']
# nxb                      = 0
# nxe                      = 0
# wavefront_size           = 32
# cumode                   = 0
# vector_c                 = 8

#--------------------------- 128x224x64
[igemm_fwd_gtc]
gemm_m_per_block         = 128
gemm_n_per_block         = 224
gemm_k_per_block         = 64
lanegroup_tile_m         = 8
lanegroup_wave_m         = 4
lanegroup_repeat_m       = 1
lanegroup_tile_n         = 16
lanegroup_wave_n         = 2
lanegroup_repeat_n       = 7
tensor_a_thread_lengths  = [1, 1, 1, 32]       # 1xCEx1xK/Vec-c
tensor_a_cluster_lengths = [1, 8, 1, 32]       # 1xCEx1xK
tensor_b_thread_lengths  = [1, 1, 7,  8]       # 1xCExNB0xVec-c
tensor_b_cluster_lengths = [1, 8, 1, 32]       # 1xCEx1xNB1
direction                = "fwd"
precision                = "fp16"
tensor_layout            = ['nchwc_cyxkc', 'nchwc_kcyxc']
nxb                      = 0
nxe                      = 1
wavefront_size           = 32
cumode                   = 0
vector_c                 = 8

[igemm_fwd_gtc]
gemm_m_per_block         = 128
gemm_n_per_block         = 224
gemm_k_per_block         = 64
lanegroup_tile_m         = 8
lanegroup_wave_m         = 4
lanegroup_repeat_m       = 1
lanegroup_tile_n         = 16
lanegroup_wave_n         = 2
lanegroup_repeat_n       = 7
tensor_a_thread_lengths  = [1, 1, 1, 32]       # 1xCEx1xK/Vec-c
tensor_a_cluster_lengths = [1, 8, 1, 32]       # 1xCEx1xK
tensor_b_thread_lengths  = [1, 1, 7,  8]       # 1xCExNB0xVec-c
tensor_b_cluster_lengths = [1, 8, 1, 32]       # 1xCEx1xNB1
direction                = "fwd"
precision                = "fp16"
tensor_layout            = ['nchwc_cyxkc', 'nchwc_kcyxc']
nxb                      = 0
nxe                      = 0
wavefront_size           = 32
cumode                   = 0
vector_c                 = 8

#--------------------------- 192x128x32
[igemm_fwd_gtc]
gemm_m_per_block         = 192
gemm_n_per_block         = 128
gemm_k_per_block         = 32
lanegroup_tile_m         = 8
lanegroup_wave_m         = 4
lanegroup_repeat_m       = 3
lanegroup_tile_n         = 16
lanegroup_wave_n         = 2
lanegroup_repeat_n       = 2
tensor_a_thread_lengths  = [1, 1, 1, 24]       # 1xCEx1xK/Vec-c
tensor_a_cluster_lengths = [1, 4, 1, 64]       # 1xCEx1xK
tensor_b_thread_lengths  = [1, 1, 2,  8]       # 1xCExNB0xVec-c
tensor_b_cluster_lengths = [1, 4, 1, 64]       # 1xCEx1xNB1
direction                = "fwd"
precision                = "fp16"
tensor_layout            = ['nchwc_cyxkc', 'nchwc_kcyxc']
nxb                      = 0
nxe                      = 1
wavefront_size           = 32
cumode                   = 0
vector_c                 = 8

[igemm_fwd_gtc]
gemm_m_per_block         = 192
gemm_n_per_block         = 128
gemm_k_per_block         = 32
lanegroup_tile_m         = 8
lanegroup_wave_m         = 4
lanegroup_repeat_m       = 3
lanegroup_tile_n         = 16
lanegroup_wave_n         = 2
lanegroup_repeat_n       = 2
tensor_a_thread_lengths  = [1, 1, 1, 24]       # 1xCEx1xK/Vec-c
tensor_a_cluster_lengths = [1, 4, 1, 64]       # 1xCEx1xK
tensor_b_thread_lengths  = [1, 1, 2,  8]       # 1xCExNB0xVec-c
tensor_b_cluster_lengths = [1, 4, 1, 64]       # 1xCEx1xNB1
direction                = "fwd"
precision                = "fp16"
tensor_layout            = ['nchwc_cyxkc', 'nchwc_kcyxc']
nxb                      = 0
nxe                      = 0
wavefront_size           = 32
cumode                   = 0
vector_c                 = 8

#--------------------------- 128x192x32
[igemm_fwd_gtc]
gemm_m_per_block         = 128
gemm_n_per_block         = 192
gemm_k_per_block         = 32
lanegroup_tile_m         = 8
lanegroup_wave_m         = 4
lanegroup_repeat_m       = 2
lanegroup_tile_n         = 16
lanegroup_wave_n         = 2
lanegroup_repeat_n       = 3
tensor_a_thread_lengths  = [1, 1, 1, 16]       # 1xCEx1xK/Vec-c
tensor_a_cluster_lengths = [1, 4, 1, 64]       # 1xCEx1xK
tensor_b_thread_lengths  = [1, 1, 3,  8]       # 1xCExNB0xVec-c
tensor_b_cluster_lengths = [1, 4, 1, 64]       # 1xCEx1xNB1
direction                = "fwd"
precision                = "fp16"
tensor_layout            = ['nchwc_cyxkc', 'nchwc_kcyxc']
nxb                      = 0
nxe                      = 1
wavefront_size           = 32
cumode                   = 0
vector_c                 = 8

[igemm_fwd_gtc]
gemm_m_per_block         = 128
gemm_n_per_block         = 192
gemm_k_per_block         = 32
lanegroup_tile_m         = 8
lanegroup_wave_m         = 4
lanegroup_repeat_m       = 2
lanegroup_tile_n         = 16
lanegroup_wave_n         = 2
lanegroup_repeat_n       = 3
tensor_a_thread_lengths  = [1, 1, 1, 16]       # 1xCEx1xK/Vec-c
tensor_a_cluster_lengths = [1, 4, 1, 64]       # 1xCEx1xK
tensor_b_thread_lengths  = [1, 1, 3,  8]       # 1xCExNB0xVec-c
tensor_b_cluster_lengths = [1, 4, 1, 64]       # 1xCEx1xNB1
direction                = "fwd"
precision                = "fp16"
tensor_layout            = ['nchwc_cyxkc', 'nchwc_kcyxc']
nxb                      = 0
nxe                      = 0
wavefront_size           = 32
cumode                   = 0
vector_c                 = 8

#--------------------------- 192x64x32
[igemm_fwd_gtc]
gemm_m_per_block         = 192
gemm_n_per_block         = 64
gemm_k_per_block         = 32
lanegroup_tile_m         = 8
lanegroup_wave_m         = 4
lanegroup_repeat_m       = 3
lanegroup_tile_n         = 16
lanegroup_wave_n         = 2
lanegroup_repeat_n       = 1
tensor_a_thread_lengths  = [1, 1, 1, 24]       # 1xCEx1xK/Vec-c
tensor_a_cluster_lengths = [1, 4, 1, 64]       # 1xCEx1xK
tensor_b_thread_lengths  = [1, 1, 1,  8]       # 1xCExNB0xVec-c
tensor_b_cluster_lengths = [1, 4, 1, 64]       # 1xCEx1xNB1
direction                = "fwd"
precision                = "fp16"
tensor_layout            = ['nchwc_cyxkc', 'nchwc_kcyxc']
nxb                      = 0
nxe                      = 1
wavefront_size           = 32
cumode                   = 0
vector_c                 = 8

[igemm_fwd_gtc]
gemm_m_per_block         = 192
gemm_n_per_block         = 64
gemm_k_per_block         = 32
lanegroup_tile_m         = 8
lanegroup_wave_m         = 4
lanegroup_repeat_m       = 3
lanegroup_tile_n         = 16
lanegroup_wave_n         = 2
lanegroup_repeat_n       = 1
tensor_a_thread_lengths  = [1, 1, 1, 24]       # 1xCEx1xK/Vec-c
tensor_a_cluster_lengths = [1, 4, 1, 64]       # 1xCEx1xK
tensor_b_thread_lengths  = [1, 1, 1,  8]       # 1xCExNB0xVec-c
tensor_b_cluster_lengths = [1, 4, 1, 64]       # 1xCEx1xNB1
direction                = "fwd"
precision                = "fp16"
tensor_layout            = ['nchwc_cyxkc', 'nchwc_kcyxc']
nxb                      = 0
nxe                      = 0
wavefront_size           = 32
cumode                   = 0
vector_c                 = 8

#--------------------------- 64x192x32
[igemm_fwd_gtc]
gemm_m_per_block         = 64
gemm_n_per_block         = 192
gemm_k_per_block         = 32
lanegroup_tile_m         = 8
lanegroup_wave_m         = 2
lanegroup_repeat_m       = 1
lanegroup_tile_n         = 16
lanegroup_wave_n         = 4
lanegroup_repeat_n       = 3
tensor_a_thread_lengths  = [1, 1, 1,  8]       # 1xCEx1xK/Vec-c
tensor_a_cluster_lengths = [1, 4, 1, 64]       # 1xCEx1xK
tensor_b_thread_lengths  = [1, 1, 3,  8]       # 1xCExNB0xVec-c
tensor_b_cluster_lengths = [1, 4, 1, 64]       # 1xCEx1xNB1
direction                = "fwd"
precision                = "fp16"
tensor_layout            = ['nchwc_cyxkc', 'nchwc_kcyxc']
nxb                      = 0
nxe                      = 1
wavefront_size           = 32
cumode                   = 0
vector_c                 = 8

[igemm_fwd_gtc]
gemm_m_per_block         = 64
gemm_n_per_block         = 192
gemm_k_per_block         = 32
lanegroup_tile_m         = 8
lanegroup_wave_m         = 2
lanegroup_repeat_m       = 1
lanegroup_tile_n         = 16
lanegroup_wave_n         = 4
lanegroup_repeat_n       = 3
tensor_a_thread_lengths  = [1, 1, 1,  8]       # 1xCEx1xK/Vec-c
tensor_a_cluster_lengths = [1, 4, 1, 64]       # 1xCEx1xK
tensor_b_thread_lengths  = [1, 1, 3,  8]       # 1xCExNB0xVec-c
tensor_b_cluster_lengths = [1, 4, 1, 64]       # 1xCEx1xNB1
direction                = "fwd"
precision                = "fp16"
tensor_layout            = ['nchwc_cyxkc', 'nchwc_kcyxc']
nxb                      = 0
nxe                      = 0
wavefront_size           = 32
cumode                   = 0
vector_c                 = 8


# #--------------------------- 160x128x64
# [igemm_fwd_gtc]
# gemm_m_per_block         = 160
# gemm_n_per_block         = 128
# gemm_k_per_block         = 64
# lanegroup_tile_m         = 8
# lanegroup_wave_m         = 4
# lanegroup_repeat_m       = 5
# lanegroup_tile_n         = 16
# lanegroup_wave_n         = 2
# lanegroup_repeat_n       = 1
# tensor_a_thread_lengths  = [1, 1, 1, 40]       # 1xCEx1xK/Vec-c
# tensor_a_cluster_lengths = [1, 8, 1, 32]       # 1xCEx1xK
# tensor_b_thread_lengths  = [1, 1, 4,  8]       # 1xCExNB0xVec-c
# tensor_b_cluster_lengths = [1, 8, 1, 32]       # 1xCEx1xNB1
# direction                = "fwd"
# precision                = "fp16"
# tensor_layout            = ['nchwc_cyxkc', 'nchwc_kcyxc']
# nxb                      = 0
# nxe                      = 1
# wavefront_size           = 32
# cumode                   = 0
# vector_c                 = 8
# 
# [igemm_fwd_gtc]
# gemm_m_per_block         = 160
# gemm_n_per_block         = 128
# gemm_k_per_block         = 64
# lanegroup_tile_m         = 8
# lanegroup_wave_m         = 4
# lanegroup_repeat_m       = 5
# lanegroup_tile_n         = 16
# lanegroup_wave_n         = 2
# lanegroup_repeat_n       = 1
# tensor_a_thread_lengths  = [1, 1, 1, 40]       # 1xCEx1xK/Vec-c
# tensor_a_cluster_lengths = [1, 8, 1, 32]       # 1xCEx1xK
# tensor_b_thread_lengths  = [1, 1, 4,  8]       # 1xCExNB0xVec-c
# tensor_b_cluster_lengths = [1, 8, 1, 32]       # 1xCEx1xNB1
# direction                = "fwd"
# precision                = "fp16"
# tensor_layout            = ['nchwc_cyxkc', 'nchwc_kcyxc']
# nxb                      = 0
# nxe                      = 0
# wavefront_size           = 32
# cumode                   = 0
# vector_c                 = 8

#--------------------------- 128x160x64
[igemm_fwd_gtc]
gemm_m_per_block         = 128
gemm_n_per_block         = 160
gemm_k_per_block         = 64
lanegroup_tile_m         = 8
lanegroup_wave_m         = 4
lanegroup_repeat_m       = 1
lanegroup_tile_n         = 16
lanegroup_wave_n         = 2
lanegroup_repeat_n       = 5
tensor_a_thread_lengths  = [1, 1, 1, 32]       # 1xCEx1xK/Vec-c
tensor_a_cluster_lengths = [1, 8, 1, 32]       # 1xCEx1xK
tensor_b_thread_lengths  = [1, 1, 5,  8]       # 1xCExNB0xVec-c
tensor_b_cluster_lengths = [1, 8, 1, 32]       # 1xCEx1xNB1
direction                = "fwd"
precision                = "fp16"
tensor_layout            = ['nchwc_cyxkc', 'nchwc_kcyxc']
nxb                      = 0
nxe                      = 1
wavefront_size           = 32
cumode                   = 0
vector_c                 = 8

[igemm_fwd_gtc]
gemm_m_per_block         = 128
gemm_n_per_block         = 160
gemm_k_per_block         = 64
lanegroup_tile_m         = 8
lanegroup_wave_m         = 4
lanegroup_repeat_m       = 1
lanegroup_tile_n         = 16
lanegroup_wave_n         = 2
lanegroup_repeat_n       = 5
tensor_a_thread_lengths  = [1, 1, 1, 32]       # 1xCEx1xK/Vec-c
tensor_a_cluster_lengths = [1, 8, 1, 32]       # 1xCEx1xK
tensor_b_thread_lengths  = [1, 1, 5,  8]       # 1xCExNB0xVec-c
tensor_b_cluster_lengths = [1, 8, 1, 32]       # 1xCEx1xNB1
direction                = "fwd"
precision                = "fp16"
tensor_layout            = ['nchwc_cyxkc', 'nchwc_kcyxc']
nxb                      = 0
nxe                      = 0
wavefront_size           = 32
cumode                   = 0
vector_c                 = 8

# #--------------------------- 160x64x32
# [igemm_fwd_gtc]
# gemm_m_per_block         = 160
# gemm_n_per_block         = 64
# gemm_k_per_block         = 32
# lanegroup_tile_m         = 8
# lanegroup_wave_m         = 4
# lanegroup_repeat_m       = 5
# lanegroup_tile_n         = 16
# lanegroup_wave_n         = 1
# lanegroup_repeat_n       = 1
# tensor_a_thread_lengths  = [1, 1, 1, 40]       # 1xCEx1xK/Vec-c
# tensor_a_cluster_lengths = [1, 4, 1, 32]       # 1xCEx1xK
# tensor_b_thread_lengths  = [1, 1, 2,  8]       # 1xCExNB0xVec-c
# tensor_b_cluster_lengths = [1, 4, 1, 32]       # 1xCEx1xNB1
# direction                = "fwd"
# precision                = "fp16"
# tensor_layout            = ['nchwc_cyxkc', 'nchwc_kcyxc']
# nxb                      = 0
# nxe                      = 1
# wavefront_size           = 32
# cumode                   = 0
# vector_c                 = 8
# 
# [igemm_fwd_gtc]
# gemm_m_per_block         = 160
# gemm_n_per_block         = 64
# gemm_k_per_block         = 32
# lanegroup_tile_m         = 8
# lanegroup_wave_m         = 4
# lanegroup_repeat_m       = 5
# lanegroup_tile_n         = 16
# lanegroup_wave_n         = 1
# lanegroup_repeat_n       = 1
# tensor_a_thread_lengths  = [1, 1, 1, 40]       # 1xCEx1xK/Vec-c
# tensor_a_cluster_lengths = [1, 4, 1, 32]       # 1xCEx1xK
# tensor_b_thread_lengths  = [1, 1, 2,  8]       # 1xCExNB0xVec-c
# tensor_b_cluster_lengths = [1, 4, 1, 32]       # 1xCEx1xNB1
# direction                = "fwd"
# precision                = "fp16"
# tensor_layout            = ['nchwc_cyxkc', 'nchwc_kcyxc']
# nxb                      = 0
# nxe                      = 0
# wavefront_size           = 32
# cumode                   = 0
# vector_c                 = 8
# 
# #--------------------------- 64x160x32
# [igemm_fwd_gtc]
# gemm_m_per_block         = 64
# gemm_n_per_block         = 160
# gemm_k_per_block         = 32
# lanegroup_tile_m         = 8
# lanegroup_wave_m         = 2
# lanegroup_repeat_m       = 1
# lanegroup_tile_n         = 16
# lanegroup_wave_n         = 2
# lanegroup_repeat_n       = 5
# tensor_a_thread_lengths  = [1, 1, 1, 16]       # 1xCEx1xK/Vec-c
# tensor_a_cluster_lengths = [1, 4, 1, 32]       # 1xCEx1xK
# tensor_b_thread_lengths  = [1, 1, 5,  8]       # 1xCExNB0xVec-c
# tensor_b_cluster_lengths = [1, 4, 1, 32]       # 1xCEx1xNB1
# direction                = "fwd"
# precision                = "fp16"
# tensor_layout            = ['nchwc_cyxkc', 'nchwc_kcyxc']
# nxb                      = 0
# nxe                      = 1
# wavefront_size           = 32
# cumode                   = 0
# vector_c                 = 8
# 
# [igemm_fwd_gtc]
# gemm_m_per_block         = 64
# gemm_n_per_block         = 160
# gemm_k_per_block         = 32
# lanegroup_tile_m         = 8
# lanegroup_wave_m         = 2
# lanegroup_repeat_m       = 1
# lanegroup_tile_n         = 16
# lanegroup_wave_n         = 2
# lanegroup_repeat_n       = 5
# tensor_a_thread_lengths  = [1, 1, 1, 16]       # 1xCEx1xK/Vec-c
# tensor_a_cluster_lengths = [1, 4, 1, 32]       # 1xCEx1xK
# tensor_b_thread_lengths  = [1, 1, 5,  8]       # 1xCExNB0xVec-c
# tensor_b_cluster_lengths = [1, 4, 1, 32]       # 1xCEx1xNB1
# direction                = "fwd"
# precision                = "fp16"
# tensor_layout            = ['nchwc_cyxkc', 'nchwc_kcyxc']
# nxb                      = 0
# nxe                      = 0
# wavefront_size           = 32
# cumode                   = 0
# vector_c                 = 8

#--------------------------- 128x128x32
[igemm_fwd_gtc]
gemm_m_per_block         = 128
gemm_n_per_block         = 128
gemm_k_per_block         = 32
lanegroup_tile_m         = 8
lanegroup_wave_m         = 4
lanegroup_repeat_m       = 2
lanegroup_tile_n         = 16
lanegroup_wave_n         = 2
lanegroup_repeat_n       = 2
tensor_a_thread_lengths  = [1, 1, 1, 16]       # 1xCEx1xK/Vec-c
tensor_a_cluster_lengths = [1, 4, 1, 64]       # 1xCEx1xK
tensor_b_thread_lengths  = [1, 1, 2,  8]       # 1xCExNB0xVec-c
tensor_b_cluster_lengths = [1, 4, 1, 64]       # 1xCEx1xNB1
direction                = "fwd"
precision                = "fp16"
tensor_layout            = ['nchwc_cyxkc', 'nchwc_kcyxc']
nxb                      = 0
nxe                      = 1
wavefront_size           = 32
cumode                   = 0
vector_c                 = 8

[igemm_fwd_gtc]
gemm_m_per_block         = 128
gemm_n_per_block         = 128
gemm_k_per_block         = 32
lanegroup_tile_m         = 8
lanegroup_wave_m         = 4
lanegroup_repeat_m       = 2
lanegroup_tile_n         = 16
lanegroup_wave_n         = 2
lanegroup_repeat_n       = 2
tensor_a_thread_lengths  = [1, 1, 1, 16]       # 1xCEx1xK/Vec-c
tensor_a_cluster_lengths = [1, 4, 1, 64]       # 1xCEx1xK
tensor_b_thread_lengths  = [1, 1, 2,  8]       # 1xCExNB0xVec-c
tensor_b_cluster_lengths = [1, 4, 1, 64]       # 1xCEx1xNB1
direction                = "fwd"
precision                = "fp16"
tensor_layout            = ['nchwc_cyxkc', 'nchwc_kcyxc']
nxb                      = 0
nxe                      = 0
wavefront_size           = 32
cumode                   = 0
vector_c                 = 8

#--------------------------- 128x96x64
[igemm_fwd_gtc]
gemm_m_per_block         = 128
gemm_n_per_block         = 96
gemm_k_per_block         = 64
lanegroup_tile_m         = 8
lanegroup_wave_m         = 4
lanegroup_repeat_m       = 1
lanegroup_tile_n         = 16
lanegroup_wave_n         = 2
lanegroup_repeat_n       = 3
tensor_a_thread_lengths  = [1, 1, 1, 32]       # 1xCEx1xK/Vec-c
tensor_a_cluster_lengths = [1, 8, 1, 32]       # 1xCEx1xK
tensor_b_thread_lengths  = [1, 1, 3,  8]       # 1xCExNB0xVec-c
tensor_b_cluster_lengths = [1, 8, 1, 32]       # 1xCEx1xNB1
direction                = "fwd"
precision                = "fp16"
tensor_layout            = ['nchwc_cyxkc', 'nchwc_kcyxc']
nxb                      = 0
nxe                      = 1
wavefront_size           = 32
cumode                   = 0
vector_c                 = 8

[igemm_fwd_gtc]
gemm_m_per_block         = 128
gemm_n_per_block         = 96
gemm_k_per_block         = 64
lanegroup_tile_m         = 8
lanegroup_wave_m         = 4
lanegroup_repeat_m       = 1
lanegroup_tile_n         = 16
lanegroup_wave_n         = 2
lanegroup_repeat_n       = 3
tensor_a_thread_lengths  = [1, 1, 1, 32]       # 1xCEx1xK/Vec-c
tensor_a_cluster_lengths = [1, 8, 1, 32]       # 1xCEx1xK
tensor_b_thread_lengths  = [1, 1, 3,  8]       # 1xCExNB0xVec-c
tensor_b_cluster_lengths = [1, 8, 1, 32]       # 1xCEx1xNB1
direction                = "fwd"
precision                = "fp16"
tensor_layout            = ['nchwc_cyxkc', 'nchwc_kcyxc']
nxb                      = 0
nxe                      = 0
wavefront_size           = 32
cumode                   = 0
vector_c                 = 8

#--------------------------- 96x128x64
[igemm_fwd_gtc]
gemm_m_per_block         = 96
gemm_n_per_block         = 128
gemm_k_per_block         = 64
lanegroup_tile_m         = 8
lanegroup_wave_m         = 4
lanegroup_repeat_m       = 3
lanegroup_tile_n         = 16
lanegroup_wave_n         = 2
lanegroup_repeat_n       = 1
tensor_a_thread_lengths  = [1, 1, 1, 24]       # 1xCEx1xK/Vec-c
tensor_a_cluster_lengths = [1, 8, 1, 32]       # 1xCEx1xK
tensor_b_thread_lengths  = [1, 1, 4,  8]       # 1xCExNB0xVec-c
tensor_b_cluster_lengths = [1, 8, 1, 32]       # 1xCEx1xNB1
direction                = "fwd"
precision                = "fp16"
tensor_layout            = ['nchwc_cyxkc', 'nchwc_kcyxc']
nxb                      = 0
nxe                      = 1
wavefront_size           = 32
cumode                   = 0
vector_c                 = 8

[igemm_fwd_gtc]
gemm_m_per_block         = 96
gemm_n_per_block         = 128
gemm_k_per_block         = 64
lanegroup_tile_m         = 8
lanegroup_wave_m         = 4
lanegroup_repeat_m       = 3
lanegroup_tile_n         = 16
lanegroup_wave_n         = 2
lanegroup_repeat_n       = 1
tensor_a_thread_lengths  = [1, 1, 1, 24]       # 1xCEx1xK/Vec-c
tensor_a_cluster_lengths = [1, 8, 1, 32]       # 1xCEx1xK
tensor_b_thread_lengths  = [1, 1, 4,  8]       # 1xCExNB0xVec-c
tensor_b_cluster_lengths = [1, 8, 1, 32]       # 1xCEx1xNB1
direction                = "fwd"
precision                = "fp16"
tensor_layout            = ['nchwc_cyxkc', 'nchwc_kcyxc']
nxb                      = 0
nxe                      = 0
wavefront_size           = 32
cumode                   = 0
vector_c                 = 8

# #--------------------------- 96x96x16
# [igemm_fwd_gtc]
# gemm_m_per_block         = 96
# gemm_n_per_block         = 96
# gemm_k_per_block         = 16
# lanegroup_tile_m         = 8
# lanegroup_wave_m         = 2
# lanegroup_repeat_m       = 3
# lanegroup_tile_n         = 16
# lanegroup_wave_n         = 2
# lanegroup_repeat_n       = 3
# tensor_a_thread_lengths  = [1, 1, 1, 24]       # 1xCEx1xK/Vec-c
# tensor_a_cluster_lengths = [1, 2, 1, 32]       # 1xCEx1xK
# tensor_b_thread_lengths  = [1, 1, 3,  8]       # 1xCExNB0xVec-c
# tensor_b_cluster_lengths = [1, 2, 1, 32]       # 1xCEx1xNB1
# direction                = "fwd"
# precision                = "fp16"
# tensor_layout            = ['nchwc_cyxkc', 'nchwc_kcyxc']
# nxb                      = 0
# nxe                      = 1
# wavefront_size           = 32
# cumode                   = 0
# vector_c                 = 8
# 
# [igemm_fwd_gtc]
# gemm_m_per_block         = 96
# gemm_n_per_block         = 96
# gemm_k_per_block         = 16
# lanegroup_tile_m         = 8
# lanegroup_wave_m         = 2
# lanegroup_repeat_m       = 3
# lanegroup_tile_n         = 16
# lanegroup_wave_n         = 2
# lanegroup_repeat_n       = 3
# tensor_a_thread_lengths  = [1, 1, 1, 24]       # 1xCEx1xK/Vec-c
# tensor_a_cluster_lengths = [1, 2, 1, 32]       # 1xCEx1xK
# tensor_b_thread_lengths  = [1, 1, 3,  8]       # 1xCExNB0xVec-c
# tensor_b_cluster_lengths = [1, 2, 1, 32]       # 1xCEx1xNB1
# direction                = "fwd"
# precision                = "fp16"
# tensor_layout            = ['nchwc_cyxkc', 'nchwc_kcyxc']
# nxb                      = 0
# nxe                      = 0
# wavefront_size           = 32
# cumode                   = 0
# vector_c                 = 8

#--------------------------- 128x64x32
[igemm_fwd_gtc]
gemm_m_per_block         = 128
gemm_n_per_block         = 64
gemm_k_per_block         = 32
lanegroup_tile_m         = 8
lanegroup_wave_m         = 4
lanegroup_repeat_m       = 2
lanegroup_tile_n         = 16
lanegroup_wave_n         = 2
lanegroup_repeat_n       = 1
tensor_a_thread_lengths  = [1, 1, 1, 16]       # 1xCEx1xK/Vec-c
tensor_a_cluster_lengths = [1, 4, 1, 64]       # 1xCEx1xK
tensor_b_thread_lengths  = [1, 1, 1,  8]       # 1xCExNB0xVec-c
tensor_b_cluster_lengths = [1, 4, 1, 64]       # 1xCEx1xNB1
direction                = "fwd"
precision                = "fp16"
tensor_layout            = ['nchwc_cyxkc', 'nchwc_kcyxc']
nxb                      = 0
nxe                      = 1
wavefront_size           = 32
cumode                   = 0
vector_c                 = 8

#--------------------------- 128x64x32
[igemm_fwd_gtc]
gemm_m_per_block         = 128
gemm_n_per_block         = 64
gemm_k_per_block         = 32
lanegroup_tile_m         = 8
lanegroup_wave_m         = 4
lanegroup_repeat_m       = 2
lanegroup_tile_n         = 16
lanegroup_wave_n         = 2
lanegroup_repeat_n       = 1
tensor_a_thread_lengths  = [1, 1, 1, 16]       # 1xCEx1xK/Vec-c
tensor_a_cluster_lengths = [1, 4, 1, 64]       # 1xCEx1xK
tensor_b_thread_lengths  = [1, 1, 1,  8]       # 1xCExNB0xVec-c
tensor_b_cluster_lengths = [1, 4, 1, 64]       # 1xCEx1xNB1
direction                = "fwd"
precision                = "fp16"
tensor_layout            = ['nchwc_cyxkc', 'nchwc_kcyxc']
nxb                      = 0
nxe                      = 0
wavefront_size           = 32
cumode                   = 0
vector_c                 = 8

#--------------------------- 64x128x32
[igemm_fwd_gtc]
gemm_m_per_block         = 64
gemm_n_per_block         = 128
gemm_k_per_block         = 32
lanegroup_tile_m         = 8
lanegroup_wave_m         = 2
lanegroup_repeat_m       = 2
lanegroup_tile_n         = 16
lanegroup_wave_n         = 4
lanegroup_repeat_n       = 1
tensor_a_thread_lengths  = [1, 1, 1,  8]       # 1xCEx1xK/Vec-c
tensor_a_cluster_lengths = [1, 4, 1, 64]       # 1xCEx1xK
tensor_b_thread_lengths  = [1, 1, 2,  8]       # 1xCExNB0xVec-c
tensor_b_cluster_lengths = [1, 4, 1, 64]       # 1xCEx1xNB1
direction                = "fwd"
precision                = "fp16"
tensor_layout            = ['nchwc_cyxkc', 'nchwc_kcyxc']
nxb                      = 0
nxe                      = 1
wavefront_size           = 32
cumode                   = 0
vector_c                 = 8

[igemm_fwd_gtc]
gemm_m_per_block         = 64
gemm_n_per_block         = 128
gemm_k_per_block         = 32
lanegroup_tile_m         = 8
lanegroup_wave_m         = 2
lanegroup_repeat_m       = 2
lanegroup_tile_n         = 16
lanegroup_wave_n         = 4
lanegroup_repeat_n       = 1
tensor_a_thread_lengths  = [1, 1, 1,  8]       # 1xCEx1xK/Vec-c
tensor_a_cluster_lengths = [1, 4, 1, 64]       # 1xCEx1xK
tensor_b_thread_lengths  = [1, 1, 2,  8]       # 1xCExNB0xVec-c
tensor_b_cluster_lengths = [1, 4, 1, 64]       # 1xCEx1xNB1
direction                = "fwd"
precision                = "fp16"
tensor_layout            = ['nchwc_cyxkc', 'nchwc_kcyxc']
nxb                      = 0
nxe                      = 0
wavefront_size           = 32
cumode                   = 0
vector_c                 = 8

#--------------------------- 128x32x32
[igemm_fwd_gtc]
gemm_m_per_block         = 128
gemm_n_per_block         = 32
gemm_k_per_block         = 32
lanegroup_tile_m         = 8
lanegroup_wave_m         = 4
lanegroup_repeat_m       = 2
lanegroup_tile_n         = 16
lanegroup_wave_n         = 1
lanegroup_repeat_n       = 1
tensor_a_thread_lengths  = [1, 1, 1, 32]       # 1xCEx1xK/Vec-c
tensor_a_cluster_lengths = [1, 4, 1, 32]       # 1xCEx1xK
tensor_b_thread_lengths  = [1, 1, 1,  8]       # 1xCExNB0xVec-c
tensor_b_cluster_lengths = [1, 4, 1, 32]       # 1xCEx1xNB1
direction                = "fwd"
precision                = "fp16"
tensor_layout            = ['nchwc_cyxkc', 'nchwc_kcyxc']
nxb                      = 0
nxe                      = 1
wavefront_size           = 32
cumode                   = 0
vector_c                 = 8

[igemm_fwd_gtc]
gemm_m_per_block         = 128
gemm_n_per_block         = 32
gemm_k_per_block         = 32
lanegroup_tile_m         = 8
lanegroup_wave_m         = 4
lanegroup_repeat_m       = 2
lanegroup_tile_n         = 16
lanegroup_wave_n         = 1
lanegroup_repeat_n       = 1
tensor_a_thread_lengths  = [1, 1, 1, 32]       # 1xCEx1xK/Vec-c
tensor_a_cluster_lengths = [1, 4, 1, 32]       # 1xCEx1xK
tensor_b_thread_lengths  = [1, 1, 1,  8]       # 1xCExNB0xVec-c
tensor_b_cluster_lengths = [1, 4, 1, 32]       # 1xCEx1xNB1
direction                = "fwd"
precision                = "fp16"
tensor_layout            = ['nchwc_cyxkc', 'nchwc_kcyxc']
nxb                      = 0
nxe                      = 0
wavefront_size           = 32
cumode                   = 0
vector_c                 = 8

#--------------------------- 32x128x32
[igemm_fwd_gtc]
gemm_m_per_block         = 32
gemm_n_per_block         = 128
gemm_k_per_block         = 32
lanegroup_tile_m         = 8
lanegroup_wave_m         = 2
lanegroup_repeat_m       = 1
lanegroup_tile_n         = 16
lanegroup_wave_n         = 2
lanegroup_repeat_n       = 2
tensor_a_thread_lengths  = [1, 1, 1,  8]       # 1xCEx1xK/Vec-c
tensor_a_cluster_lengths = [1, 4, 1, 32]       # 1xCEx1xK
tensor_b_thread_lengths  = [1, 1, 4,  8]       # 1xCExNB0xVec-c
tensor_b_cluster_lengths = [1, 4, 1, 32]       # 1xCEx1xNB1
direction                = "fwd"
precision                = "fp16"
tensor_layout            = ['nchwc_cyxkc', 'nchwc_kcyxc']
nxb                      = 0
nxe                      = 1
wavefront_size           = 32
cumode                   = 0
vector_c                 = 8

[igemm_fwd_gtc]
gemm_m_per_block         = 32
gemm_n_per_block         = 128
gemm_k_per_block         = 32
lanegroup_tile_m         = 8
lanegroup_wave_m         = 2
lanegroup_repeat_m       = 1
lanegroup_tile_n         = 16
lanegroup_wave_n         = 2
lanegroup_repeat_n       = 2
tensor_a_thread_lengths  = [1, 1, 1,  8]       # 1xCEx1xK/Vec-c
tensor_a_cluster_lengths = [1, 4, 1, 32]       # 1xCEx1xK
tensor_b_thread_lengths  = [1, 1, 4,  8]       # 1xCExNB0xVec-c
tensor_b_cluster_lengths = [1, 4, 1, 32]       # 1xCEx1xNB1
direction                = "fwd"
precision                = "fp16"
tensor_layout            = ['nchwc_cyxkc', 'nchwc_kcyxc']
nxb                      = 0
nxe                      = 0
wavefront_size           = 32
cumode                   = 0
vector_c                 = 8

#--------------------------- 64x64x64
[igemm_fwd_gtc]
gemm_m_per_block         = 64
gemm_n_per_block         = 64
gemm_k_per_block         = 64
lanegroup_tile_m         = 8
lanegroup_wave_m         = 2
lanegroup_repeat_m       = 2
lanegroup_tile_n         = 16
lanegroup_wave_n         = 2
lanegroup_repeat_n       = 1
tensor_a_thread_lengths  = [1, 1, 1, 32]       # 1xCEx1xK/Vec-c
tensor_a_cluster_lengths = [1, 8, 1, 16]       # 1xCEx1xK
tensor_b_thread_lengths  = [1, 1, 4,  8]       # 1xCExNB0xVec-c
tensor_b_cluster_lengths = [1, 8, 1, 16]       # 1xCEx1xNB1
direction                = "fwd"
precision                = "fp16"
tensor_layout            = ['nchwc_cyxkc', 'nchwc_kcyxc']
nxb                      = 0
nxe                      = 1
wavefront_size           = 32
cumode                   = 0
vector_c                 = 8

[igemm_fwd_gtc]
gemm_m_per_block         = 64
gemm_n_per_block         = 64
gemm_k_per_block         = 64
lanegroup_tile_m         = 8
lanegroup_wave_m         = 2
lanegroup_repeat_m       = 2
lanegroup_tile_n         = 16
lanegroup_wave_n         = 2
lanegroup_repeat_n       = 1
tensor_a_thread_lengths  = [1, 1, 1, 32]       # 1xCEx1xK/Vec-c
tensor_a_cluster_lengths = [1, 8, 1, 16]       # 1xCEx1xK
tensor_b_thread_lengths  = [1, 1, 4,  8]       # 1xCExNB0xVec-c
tensor_b_cluster_lengths = [1, 8, 1, 16]       # 1xCEx1xNB1
direction                = "fwd"
precision                = "fp16"
tensor_layout            = ['nchwc_cyxkc', 'nchwc_kcyxc']
nxb                      = 0
nxe                      = 0
wavefront_size           = 32
cumode                   = 0
vector_c                 = 8

#--------------------------- 64x64x32
[igemm_fwd_gtc]
gemm_m_per_block         = 64
gemm_n_per_block         = 64
gemm_k_per_block         = 32
lanegroup_tile_m         = 8
lanegroup_wave_m         = 2
lanegroup_repeat_m       = 2
lanegroup_tile_n         = 16
lanegroup_wave_n         = 2
lanegroup_repeat_n       = 1
tensor_a_thread_lengths  = [1, 1, 1, 16]       # 1xCEx1xK/Vec-c
tensor_a_cluster_lengths = [1, 4, 1, 32]       # 1xCEx1xK
tensor_b_thread_lengths  = [1, 1, 2,  8]       # 1xCExNB0xVec-c
tensor_b_cluster_lengths = [1, 4, 1, 32]       # 1xCEx1xNB1
direction                = "fwd"
precision                = "fp16"
tensor_layout            = ['nchwc_cyxkc', 'nchwc_kcyxc']
nxb                      = 0
nxe                      = 1
wavefront_size           = 32
cumode                   = 0
vector_c                 = 8

[igemm_fwd_gtc]
gemm_m_per_block         = 64
gemm_n_per_block         = 64
gemm_k_per_block         = 32
lanegroup_tile_m         = 8
lanegroup_wave_m         = 2
lanegroup_repeat_m       = 2
lanegroup_tile_n         = 16
lanegroup_wave_n         = 2
lanegroup_repeat_n       = 1
tensor_a_thread_lengths  = [1, 1, 1, 16]       # 1xCEx1xK/Vec-c
tensor_a_cluster_lengths = [1, 4, 1, 32]       # 1xCEx1xK
tensor_b_thread_lengths  = [1, 1, 2,  8]       # 1xCExNB0xVec-c
tensor_b_cluster_lengths = [1, 4, 1, 32]       # 1xCEx1xNB1
direction                = "fwd"
precision                = "fp16"
tensor_layout            = ['nchwc_cyxkc', 'nchwc_kcyxc']
nxb                      = 0
nxe                      = 0
wavefront_size           = 32
cumode                   = 0
vector_c                 = 8

#--------------------------- 64x32x32
[igemm_fwd_gtc]
gemm_m_per_block         = 64
gemm_n_per_block         = 32
gemm_k_per_block         = 32
lanegroup_tile_m         = 8
lanegroup_wave_m         = 2
lanegroup_repeat_m       = 2
lanegroup_tile_n         = 16
lanegroup_wave_n         = 2
lanegroup_repeat_n       = 1
tensor_a_thread_lengths  = [1, 1, 1, 32]       # 1xCEx1xK/Vec-c
tensor_a_cluster_lengths = [1, 4, 1, 16]       # 1xCEx1xK
tensor_b_thread_lengths  = [1, 1, 2,  8]       # 1xCExNB0xVec-c
tensor_b_cluster_lengths = [1, 4, 1, 16]       # 1xCEx1xNB1
direction                = "fwd"
precision                = "fp16"
tensor_layout            = ['nchwc_cyxkc', 'nchwc_kcyxc']
nxb                      = 0
nxe                      = 1
wavefront_size           = 32
cumode                   = 0
vector_c                 = 8

[igemm_fwd_gtc]
gemm_m_per_block         = 64
gemm_n_per_block         = 32
gemm_k_per_block         = 32
lanegroup_tile_m         = 8
lanegroup_wave_m         = 2
lanegroup_repeat_m       = 2
lanegroup_tile_n         = 16
lanegroup_wave_n         = 2
lanegroup_repeat_n       = 1
tensor_a_thread_lengths  = [1, 1, 1, 32]       # 1xCEx1xK/Vec-c
tensor_a_cluster_lengths = [1, 4, 1, 16]       # 1xCEx1xK
tensor_b_thread_lengths  = [1, 1, 2,  8]       # 1xCExNB0xVec-c
tensor_b_cluster_lengths = [1, 4, 1, 16]       # 1xCEx1xNB1
direction                = "fwd"
precision                = "fp16"
tensor_layout            = ['nchwc_cyxkc', 'nchwc_kcyxc']
nxb                      = 0
nxe                      = 0
wavefront_size           = 32
cumode                   = 0
vector_c                 = 8

#--------------------------- 32x64x32
[igemm_fwd_gtc]
gemm_m_per_block         = 32
gemm_n_per_block         = 64
gemm_k_per_block         = 32
lanegroup_tile_m         = 8
lanegroup_wave_m         = 2
lanegroup_repeat_m       = 1
lanegroup_tile_n         = 16
lanegroup_wave_n         = 2
lanegroup_repeat_n       = 2
tensor_a_thread_lengths  = [1, 1, 1, 16]       # 1xCEx1xK/Vec-c
tensor_a_cluster_lengths = [1, 4, 1, 16]       # 1xCEx1xK
tensor_b_thread_lengths  = [1, 1, 4,  8]       # 1xCExNB0xVec-c
tensor_b_cluster_lengths = [1, 4, 1, 16]       # 1xCEx1xNB1
direction                = "fwd"
precision                = "fp16"
tensor_layout            = ['nchwc_cyxkc', 'nchwc_kcyxc']
nxb                      = 0
nxe                      = 1
wavefront_size           = 32
cumode                   = 0
vector_c                 = 8

[igemm_fwd_gtc]
gemm_m_per_block         = 32
gemm_n_per_block         = 64
gemm_k_per_block         = 32
lanegroup_tile_m         = 8
lanegroup_wave_m         = 2
lanegroup_repeat_m       = 1
lanegroup_tile_n         = 16
lanegroup_wave_n         = 2
lanegroup_repeat_n       = 2
tensor_a_thread_lengths  = [1, 1, 1, 16]       # 1xCEx1xK/Vec-c
tensor_a_cluster_lengths = [1, 4, 1, 16]       # 1xCEx1xK
tensor_b_thread_lengths  = [1, 1, 4,  8]       # 1xCExNB0xVec-c
tensor_b_cluster_lengths = [1, 4, 1, 16]       # 1xCEx1xNB1
direction                = "fwd"
precision                = "fp16"
tensor_layout            = ['nchwc_cyxkc', 'nchwc_kcyxc']
nxb                      = 0
nxe                      = 0
wavefront_size           = 32
cumode                   = 0
vector_c                 = 8

#--------------------------- 32x32x16
[igemm_fwd_gtc]
gemm_m_per_block         = 32
gemm_n_per_block         = 32
gemm_k_per_block         = 16
lanegroup_tile_m         = 8
lanegroup_wave_m         = 2
lanegroup_repeat_m       = 2
lanegroup_tile_n         = 16
lanegroup_wave_n         = 2
lanegroup_repeat_n       = 1
tensor_a_thread_lengths  = [1, 1, 1, 16]       # 1xCEx1xK/Vec-c
tensor_a_cluster_lengths = [1, 2, 1, 16]       # 1xCEx1xK
tensor_b_thread_lengths  = [1, 1, 2,  8]       # 1xCExNB0xVec-c
tensor_b_cluster_lengths = [1, 2, 1, 16]       # 1xCEx1xNB1
direction                = "fwd"
precision                = "fp16"
tensor_layout            = ['nchwc_cyxkc', 'nchwc_kcyxc']
nxb                      = 0
nxe                      = 1
wavefront_size           = 32
cumode                   = 0
vector_c                 = 8

[igemm_fwd_gtc]
gemm_m_per_block         = 32
gemm_n_per_block         = 32
gemm_k_per_block         = 16
lanegroup_tile_m         = 8
lanegroup_wave_m         = 2
lanegroup_repeat_m       = 2
lanegroup_tile_n         = 16
lanegroup_wave_n         = 2
lanegroup_repeat_n       = 1
tensor_a_thread_lengths  = [1, 1, 1, 16]       # 1xCEx1xK/Vec-c
tensor_a_cluster_lengths = [1, 2, 1, 16]       # 1xCEx1xK
tensor_b_thread_lengths  = [1, 1, 2,  8]       # 1xCExNB0xVec-c
tensor_b_cluster_lengths = [1, 2, 1, 16]       # 1xCEx1xNB1
direction                = "fwd"
precision                = "fp16"
tensor_layout            = ['nchwc_cyxkc', 'nchwc_kcyxc']
nxb                      = 0
nxe                      = 0
wavefront_size           = 32
cumode                   = 0
vector_c                 = 8
